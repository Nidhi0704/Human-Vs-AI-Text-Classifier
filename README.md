*Human vs AI Text Generated Analysis*
This project aims to analyze and classify whether a given text is generated by a human or AI using machine learning techniques. A Naive Bayes model was implemented for the classification task, and the project achieved high accuracy by applying thorough data cleaning, preprocessing, and feature engineering steps.

**Table of Contents**
Introduction
Features
Technologies Used
Data Preprocessing
Modeling
Results
Installation
Usage
Contributing
License
**Introduction**
With the rise of AI-generated content, it has become increasingly important to differentiate between text written by humans and machines. This project presents a solution to classify text into two categories: Human-generated or AI-generated. The model analyzes the given input and accurately predicts the source of the text.

**Features**
Detects whether a text is written by a human or generated by AI.
High accuracy using Naive Bayes classification.
Data preprocessing including text cleaning and feature extraction.
Easy-to-use interface to input and classify text.
**Technologies Used**
Python for development
Flask for building the web interface
Naive Bayes for text classification
NLTK and spaCy for text preprocessing
Pandas and NumPy for data handling
Scikit-learn for machine learning model implementation
**Data Preprocessing**
The data goes through several stages of preprocessing to improve the model's accuracy:

Text cleaning: Removal of stopwords, special characters, and noise.
Tokenization: Breaking text into individual words.
Vectorization: Converting text into numerical features using TF-IDF or Count Vectorization.
Labeling: Assigning labels for Human-generated and AI-generated texts.
**Modeling**
We employed the Naive Bayes classifier for its simplicity and effectiveness in handling text data. The model was trained on a balanced dataset of human and AI-generated texts. Key steps include:

Splitting data into training and testing sets.

Training the Naive Bayes model on the preprocessed text.

Tuning hyperparameters to achieve the best accuracy.
**Results**
The final model delivered high accuracy, making reliable predictions on whether a given text is written by a human or generated by AI. Accuracy and performance metrics were calculated using:

**Accuracy score**
Precision
Recall
F1-score

**Contributing**
Contributions are welcome! Please create a pull request or raise an issue if you'd like to contribute to this project.
